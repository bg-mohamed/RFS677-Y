{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des librairies"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Requirements :\n",
    "pandas_profiling==3.0.0\n",
    "xgboost==1.4.2\n",
    "imblearn==0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas_profiling import ProfileReport\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.offline as py\n",
    "import seaborn as sns\n",
    "import plotly.graph_objs as go\n",
    "import plotly \n",
    "import plotly.figure_factory as ff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFE\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import *\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.<span style=\"color:red\"> Lecture des Datasets </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 <span style=\"color:black\">  Concaténation en un DataFrame pour appliquer les mêmes changements</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train,test], axis= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe(include = 'all' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.<span style=\"color:blue\"> EDA </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1<span style=\"color:black\">  Distribution de la Target </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['embauche'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **On remarque un fort déséquilibre dans la distribution de la classe \"embauche\" ce qui affectera l'apprentissage si \n",
    "    on ne procède pas à une redistribution de cette variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['embauche'].value_counts().plot(kind='pie',title= 'distribution de la Target', autopct='%.f%%', legend = False, figsize=(12,6), fontsize=12,explode = [0, 0.2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2<span style=\"color:black\"> Pandas profiling du Dataset </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "profile = ProfileReport(df, title=\"Embauche ou pas\")\n",
    "profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Les NaN & valeurs abérrantes présentes dans ce dataset:**\n",
    "\n",
    "- 5 observations dont l'age est supérieur/égal à 70 ans\n",
    "- 479 observations dont l'age est inférieur à 16 ans\n",
    "- 2 observations dont l'expérience est inférieur à 0\n",
    "- 104 observations dont l'expérience est supérieur à l'age\n",
    "- 1465 observations dont la note est supérieur à 100.\n",
    "- 908 NaN\n",
    "\n",
    "<span style=\"color:blue\">**2055 Outliers & 908 NaN soit près de 15% du dataset**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:darkorange\"> **Deux méthodologies se présentent:**</span>\n",
    "    \n",
    "   **1- Supprimer les Outliers & les NaNs**\n",
    "    \n",
    "   **2- Dans la compétition Kaggle, on était face à une contrainte majeure qui était de garder le set de Test complet à\n",
    "       5000 lignes, donc on a procédé à une \"harmonisation\" des NaN et des valeurs aberrantes**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<span style=\"color:blue\">**Outliers de la variable \"age\"**</span>\n",
    "- **On procèdera donc à la correction de l'âge en supposant un age minimal légal de travail de 16 ans et maximal de 70 ans**\n",
    "\n",
    "\n",
    "<span style=\"color:blue\">**Outliers de la variable \"diplome\"**</span>\n",
    "- **On procèdera donc à l'harmonisation de cette variable en tenant compte de la variable \"age\" comme suit :**\n",
    "\n",
    "**diplome bac--> age 18 ans / license --> 21 ans / master --> 23 ans / doctorat --> 27 ans**\n",
    "\n",
    "\n",
    "<span style=\"color:blue\">**Outliers de la variable \"note\"**</span>\n",
    "- **Etant donné le concours d'embauche est noté de 0 à 100, on considérera toutes les notes supérieures à la limite comme arrondie à 100**\n",
    "\n",
    "<span style=\"color:blue\">**Outliers de la variable \"exp\"**</span>\n",
    "- **Sur des observations ou l'expérience dépasse l'âge, cette dernière sera remplacée par la moyenne de l'expérience**\n",
    "\n",
    "<span style=\"color:red\">**Les valeurs manquantes**</span>\n",
    "- **Pour les Nan des variables numériques on imputera la moyenne (mean)**\n",
    "- **Pour les Nan des variables catégorielles on imputera le mode (mode)**\n",
    "\n",
    "<span style=\"color:green\">**Les variables corrélées**</span>\n",
    "-  **Aucune corrélation notoire ou presque n'a été détectée à part Note/Salaire à près de 40%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3<span style=\"color:black\">  Traitement des outliers </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Boxplot Diplome/Age**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.boxplot(x='diplome',\n",
    "            y='age',\n",
    "            data=df,\n",
    "            palette='winter');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Boxplot Diplome/Exp**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.boxplot(x='diplome',\n",
    "            y='exp',\n",
    "            data=df,\n",
    "            palette='winter');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Boxplot Exp/Age**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.boxplot(x='exp',\n",
    "            y='age',\n",
    "            data=df,\n",
    "            palette='winter');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------#\n",
    "df.loc[(df['age'] >= 70), 'age'] = round(df['age'].mean(), 0) #5 Observations\n",
    "df.loc[(df['age'] < 16), 'age'] = round(df['age'].mean(), 0) #479 Observations\n",
    "#------------#\n",
    "df.loc[(df['diplome'] == \"bac\"), 'age'] = 18 #2453 observations\n",
    "df.loc[(df['diplome'] == \"licence\"), 'age'] = 21 #7377 observations\n",
    "df.loc[(df['diplome'] == \"master\"), 'age'] = 23 #7513 observations\n",
    "df.loc[(df['diplome'] == \"doctorat\"), 'age'] = 27 #2547 observations\n",
    "#------------#\n",
    "df.loc[(df['exp'] < 0), 'exp'] = round(df['exp'].mean(), 0) #2 observations\n",
    "df.loc[(df['exp'] > df['age']),'exp'] = round(df['exp'].mean(),0) #104 observations\n",
    "#------------#\n",
    "df.loc[(df['note'] > 100), 'note'] = 100 #1465 observations\n",
    "#------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4<span style=\"color:black\">  Traitement des NAN </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(df.isnull(), \n",
    "            yticklabels=False, \n",
    "            cbar=False, \n",
    "            cmap='viridis');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------Variables Numériques-------#\n",
    "NUMERICAL = [\"age\",\"exp\",\"salaire\",\"note\"]\n",
    "df[NUMERICAL]= df[NUMERICAL].astype(np.float32)\n",
    "df[NUMERICAL] = df[NUMERICAL].fillna(round(df[NUMERICAL].mean(), 0))\n",
    "\n",
    "#------Variables Catégorielles-------#\n",
    "CATEGORICAL = [\"cheveux\",\"sexe\",\"diplome\",\"specialite\",\"dispo\",\"date\"]\n",
    "df[CATEGORICAL]= df[CATEGORICAL].astype('category')\n",
    "df[CATEGORICAL] = df[CATEGORICAL].fillna(df[CATEGORICAL].mode().iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5<span style=\"color:black\">  Création de nouvelles features numériques à partir de la date </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'],format=\"%Y-%m-%d\")\n",
    "df['year']=  df['date'].dt.year\n",
    "df['month']=  df['date'].dt.month\n",
    "df['day']=  df['date'].dt.day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 <span style=\"color:black\">  Création de nouvelles features catégoriques </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['q_exp'] = pd.qcut(df['exp'],q=3,precision=0)\n",
    "df['q_age'] = pd.qcut(df['age'], q=3,precision=0)\n",
    "df['q_note'] = pd.qcut(df['note'],q=4,precision=0)\n",
    "df['q_salaire'] = pd.qcut(df['salaire'],q=5,precision=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 <span style=\"color:black\"> Redéfinition des Variables numériques/catégorielles/features/Target </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERICAL = [\"age\",\"exp\",\"salaire\",\"note\",\"year\",\"month\",\"day\"]\n",
    "df[NUMERICAL]= df[NUMERICAL].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL = [\"cheveux\",\"sexe\",\"diplome\",\"specialite\",\"dispo\"]\n",
    "df[CATEGORICAL]= df[CATEGORICAL].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = NUMERICAL + CATEGORICAL + [\"q_exp\",\"q_age\",\"q_note\",'q_salaire']\n",
    "TARGET = \"embauche\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 <span style=\"color:black\"> Data Viz </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Distribution des classes de la variable AGE par rapport à la TARGET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "plt.hist(df[df[\"embauche\"]==1][\"age\"], edgecolor=\"k\",density=True, alpha=0.7, label = \"Embauché(e)\")\n",
    "plt.hist(df[df[\"embauche\"]==0][\"age\"], edgecolor=\"k\",density=True, alpha=0.7, label = \"Pas embauché(e)\")\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Distribution des classes de la variable EXP par rapport à la TARGET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "plt.hist(df[df[\"embauche\"]==1][\"exp\"], edgecolor=\"k\",density=True, alpha=0.7, label = \"Embauché(e)\")\n",
    "plt.hist(df[df[\"embauche\"]==0][\"exp\"], edgecolor=\"k\",density=True, alpha=0.7, label = \"Pas embauché(e)\")\n",
    "plt.xlabel(\"Experience\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Distribution des classes de la variable NOTE par rapport à la TARGET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "plt.hist(df[df[\"embauche\"]==1][\"note\"], edgecolor=\"k\",density=True, alpha=0.7, label = \"Embauché(e)\")\n",
    "plt.hist(df[df[\"embauche\"]==0][\"note\"], edgecolor=\"k\",density=True, alpha=0.7, label = \"Pas embauché(e)\")\n",
    "plt.xlabel(\"Note\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Distribution des classes de la variable SALAIRE par rapport à la TARGET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "plt.hist(df[df[\"embauche\"]==1][\"salaire\"], edgecolor=\"k\",density=True, alpha=0.7, label = \"Embauché(e)\")\n",
    "plt.hist(df[df[\"embauche\"]==0][\"salaire\"], edgecolor=\"k\",density=True, alpha=0.7, label = \"Pas embauché(e)\")\n",
    "plt.xlabel(\"Salaire\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Distribution des classes de la variable YEAR par rapport à la TARGET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "sns.countplot(data=df, x=\"year\",hue=\"embauche\", edgecolor=\"k\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Distribution des classes de la variable MONTH par rapport à la TARGET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "sns.countplot(data=df, x=\"month\",hue=\"embauche\", edgecolor=\"k\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Distribution des classes de la variable DAY par rapport à la TARGET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "sns.countplot(data=df, x=\"day\",hue=\"embauche\", edgecolor=\"k\")\n",
    "plt.xlabel(\"day\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Distribution de la variable CHEVEUX par rapport à la TARGET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "sns.countplot(data=df, x=\"cheveux\",hue=\"embauche\", edgecolor=\"k\")\n",
    "plt.xlabel(\"Cheveux\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Distribution de la variable DIPLOME par rapport à la TARGET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "sns.countplot(data=df, x=\"diplome\",hue=\"embauche\", edgecolor=\"k\")\n",
    "plt.xlabel(\"Diplome\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Distribution de la variable SPECIALITE par rapport à la TARGET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "sns.countplot(data=df, x=\"specialite\",hue=\"embauche\", edgecolor=\"k\")\n",
    "plt.xlabel(\"specialite\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Distribution de la variable DISPO par rapport à la variable SEXE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "sns.countplot(data=df, x=\"dispo\",hue=\"embauche\", edgecolor=\"k\")\n",
    "plt.xlabel(\"Dispo\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 <span style=\"color:black\"> Tests Statistiques </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CHEVEUX / SALAIRE**\n",
    "- Hypothèse H0 : Pas de relation statistiquement significative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_blond =df[df[\"cheveux\"]==\"blond\"]\n",
    "data_brun = df[df[\"cheveux\"]==\"brun\"]\n",
    "data_roux =df[df[\"cheveux\"]==\"roux\"]\n",
    "data_chatain =df[df[\"cheveux\"]==\"chatain\"]\n",
    "stat, p_value = scipy.stats.kruskal(data_blond[\"salaire\"], data_brun[\"salaire\"],data_roux[\"salaire\"] ,data_chatain[\"salaire\"])\n",
    "\n",
    "print('Statistics=%.3f, p_value=%.3f' % (stat, p_value))\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p_value > alpha:\n",
    "    print('Même distributions (Hypothèse H0 non rejetée)')\n",
    "else:\n",
    "    print('Distributions différentes (Hypothèse H0 rejetée)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SPECIALITE / SEXE**\n",
    "- Hypothèse H0 : Pas de relation statistiquement significative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_forage =df[df[\"specialite\"]==\"forage\"]\n",
    "data_geologie = df[df[\"specialite\"]==\"geologie\"]\n",
    "data_detective =df[df[\"specialite\"]==\"detective\"]\n",
    "data_archeologie =df[df[\"specialite\"]==\"archeologie\"]\n",
    "stat, p_value = scipy.stats.kruskal(data_forage[\"sexe\"], data_geologie[\"sexe\"],data_detective[\"sexe\"] ,\n",
    "                                    data_archeologie[\"sexe\"])\n",
    "\n",
    "print('Statistics=%.3f, p_value=%.3f' % (stat, p_value))\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p_value > alpha:\n",
    "    print('Même distributions (Hypothèse H0 non rejetée)')\n",
    "else:\n",
    "    print('Distributions différentes (Hypothèse H0 rejetée)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXP / NOTE**\n",
    "- Hypothèse H0 : Pas de relation statistiquement significative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_exp =df[\"exp\"]\n",
    "data_note = df[\"note\"]\n",
    "stat, p_value = scipy.stats.kruskal(data_exp, data_note)\n",
    "\n",
    "print('Statistics=%.3f, p_value=%.3f' % (stat, p_value))\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p_value > alpha:\n",
    "    print('Même distributions (Hypothèse H0 non rejetée)')\n",
    "else:\n",
    "    print('Distributions différentes (Hypothèse H0 rejetée)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "sns.heatmap(df.corr('spearman'),annot=False,cmap='rocket',lw=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_chi_2(QualVar,target,alpha):\n",
    "\n",
    "   \n",
    "\n",
    "    QualVar = pd.DataFrame(QualVar)\n",
    "\n",
    "    liste_chi2 = []\n",
    "\n",
    "    liste_chi2_name = []\n",
    "\n",
    "   \n",
    "\n",
    "    # ici on créé le tableau de contingence pour réaliser notre test :\n",
    "\n",
    "        \n",
    "\n",
    "    for i in range(len(list(QualVar.columns))):\n",
    "\n",
    " \n",
    "\n",
    "        table = pd.crosstab(QualVar[list(QualVar.columns)[i]],QualVar[target])\n",
    "\n",
    "        stat, p, dof, expected = chi2_contingency(table)\n",
    "\n",
    " \n",
    "        if p <= alpha:\n",
    "\n",
    "            liste_chi2.append(i)\n",
    "\n",
    "        else:\n",
    "\n",
    "            pass\n",
    "   \n",
    "\n",
    "    for j in liste_chi2:\n",
    "\n",
    "        liste_chi2_name.append([i.encode('ascii', 'ignore') for i in QualVar.columns][j])\n",
    "\n",
    "       \n",
    "\n",
    "    return liste_chi2_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "liste_chi2_name = test_chi_2(df,\"embauche\",0.05)\n",
    "liste_chi2_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les variables listées ci-dessus ont une p_value< 5% et donc présente une significativité statistique pour expliquer la TARGET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.<span style=\"color:green\"> PREPROCESSING </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1<span style=\"color:black\">  Label Encoding </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Le choix s'est porté sur le label encoding pour éviter une augumentation de la dimension créée par le One hot encoding par exemple, et ce pour plus de performance lors des Tunnings des hyperparamètres**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    "df_c[CATEGORICAL]=df[CATEGORICAL].apply(label_encoder.fit_transform)\n",
    "df_c[[\"q_exp\",\"q_age\",\"q_note\",'q_salaire']] = df[[\"q_exp\",\"q_age\",\"q_note\",'q_salaire']].apply(label_encoder.fit_transform)\n",
    "df_c[TARGET]=df[TARGET]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2<span style=\"color:black\"> Transformation du type </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c['age'] = df_c['age'].astype(np.uint8)\n",
    "df_c['exp'] = df_c['exp'].astype(np.uint8)\n",
    "df_c['salaire'] = df_c['salaire'].astype(np.uint8)\n",
    "df_c['cheveux'] = df_c['cheveux'].astype(np.uint8)\n",
    "df_c['note'] = df_c['note'].astype(np.float16)\n",
    "df_c['sexe'] = df_c['sexe'].astype(np.uint8)\n",
    "df_c['diplome'] = df_c['diplome'].astype(np.uint8)\n",
    "df_c['specialite'] = df_c['specialite'].astype(np.uint8)\n",
    "df_c['dispo'] = df_c['dispo'].astype(np.uint8)\n",
    "df_c['year'] = df_c['year'].astype(np.int16)\n",
    "df_c['month'] = df_c['month'].astype(np.int16)\n",
    "df_c['day'] = df_c['day'].astype(np.int16)\n",
    "df_c['q_exp'] = df_c['q_exp'].astype(np.int16)\n",
    "df_c['q_age'] = df_c['q_age'].astype(np.int16)\n",
    "df_c['q_salaire'] = df_c['q_salaire'].astype(np.int16)    \n",
    "df_c['q_note'] = df_c['q_note'].astype(np.int16) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3<span style=\"color:black\"> Train/Test Split </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_c.loc[~df_c[TARGET].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_c.loc[df_c[TARGET].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4<span style=\"color:black\"> Oversampling de la classe minoritaire \"embauche = 1\" </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Le SMOTETomek procédera à la création de valeurs synthétiques similaires aux vraies valeurs présentes dans le dataset avec une Embauche = 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "smotetomek_X = train[FEATURES]\n",
    "smotetomek_Y = train[TARGET]\n",
    "\n",
    "smote_tomek = SMOTETomek(random_state=68, sampling_strategy=0.99) #La classe 1 sera 99% de la classe 0\n",
    "X_resampled, y_resampled = smote_tomek.fit_resample(train[FEATURES], train[TARGET])\n",
    "\n",
    "smotetomek_X = pd.DataFrame(data = X_resampled,columns=FEATURES)\n",
    "smotetomek_Y = pd.DataFrame(data = y_resampled,columns=['embauche'])\n",
    "print ((smotetomek_Y['embauche'] == 1).sum())\n",
    "print ((smotetomek_Y['embauche'] == 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_X = smotetomek_X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y = smotetomek_Y.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X[FEATURES]\n",
    "train_Y = train_Y[TARGET]\n",
    "test_X = test[FEATURES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oversampler = pd.concat([train_X,train_Y], axis= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Distribution de la target après Oversampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_oversampler['embauche'].value_counts().plot(kind='pie',title= 'distribution de la Target', autopct='%.f%%', legend = False, figsize=(12,6), fontsize=12,explode = [0, 0.2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4<span style=\"color:black\"> Standardisation des données</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarque** : \n",
    "\n",
    "**La standardisation des données n'est pas nécessaire quand on utilise des algorithmes d'apprentissage non sensibles à l'amplitude des variables tels que**\n",
    "- La régression logistique\n",
    "- Le Random Forest\n",
    "- Les modèles de Gradient boosting\n",
    "\n",
    "**Hors dans ce projet, on utilisera aussi le SVC, DTC & KNN qui eux sont sensibles à l'amplitude des variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_X.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "train_X = scaler.fit_transform(train_X)\n",
    "test_X = scaler.fit_transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.astype('float32')\n",
    "test_X = test_X.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.<span style=\"color:Orange\"> MODELISATION </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Le projet présenté à pour but une classification de la TARGET entre 0 & 1\n",
    "\n",
    "- On choisira donc des Algorithmes d'apprentissage supervisé pour CLASSIFICATION\n",
    "\n",
    "- Régression Logistique /Decision Tree/ SVC / KNN / Random Forest / Gradient boosting / XGBoost\n",
    "\n",
    "- La comparaison des modèles se fera principalement sur le score AUC\n",
    "\n",
    "- Le tunning des hyperparamètres se fera avec HalvingGridSearchCV qui est une nouvelle classe de tunning des hyperparamètres beaucoup plus rapide que le GridsearchCV avec pratiquement les mêmes résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1<span style=\"color:black\"> Tunning des Hyperparamètres avec HalvingGridSearchCV </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tunning(param_grid,model,X,Y):    \n",
    "    halving = HalvingGridSearchCV(model, param_grid = param_grid,scoring=\"roc_auc\", min_resources = \"exhaust\",\n",
    "                                  n_jobs = -1,cv = 5, factor = 3, verbose = 1)\n",
    "    halving.fit(X, Y)\n",
    "    print (\"Best Score: {}\".format(halving.best_score_)) \n",
    "    print (\"Best params: {}\".format(halving.best_params_)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2<span style=\"color:black\"> Evaluation du modèle </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model,z,X,Y):\n",
    "    model.fit(X,Y)\n",
    "    predict   = model.predict(X)\n",
    "    proba = model.predict_proba(X)\n",
    "    fig = plt.figure()\n",
    "    #roc_auc_score\n",
    "    model_roc_auc = metrics.roc_auc_score(Y,predict) \n",
    "    #Confusion matrix\n",
    "    conf_matrix = metrics.confusion_matrix(Y,predict)\n",
    "    #plot confusion matrix\n",
    "    plot1 = go.Heatmap(z = conf_matrix ,\n",
    "                        x = [\"Pred_0\",\"Pred_1\"],\n",
    "                        y = [\"Real_0\",\"Real_1\"],\n",
    "                        showscale  = True,autocolorscale = True,\n",
    "                        name = \"matrix\", transpose = True, visible =  True)\n",
    "    #plot roc auc\n",
    "    a,b,c = metrics.roc_curve(Y,proba[:,1])\n",
    "    plot2 = go.Scatter(x = a,y = b,\n",
    "                        name = \"Roc : \" + str(model_roc_auc),\n",
    "                        line = dict(color = ('rgb(22, 96, 167)'),width = 2))\n",
    "    plot3 = go.Scatter(x = [0,1],y=[0,1],\n",
    "                        line = dict(color = ('rgb(205, 12, 24)'),width = 2,\n",
    "                        dash = 'dot'))\n",
    "    #plot coefficients/Features\n",
    "    if z == \"coefficients\" :\n",
    "        coefficients  = pd.DataFrame(model.coef_.ravel())\n",
    "    elif z== \"features\" :\n",
    "        coefficients  = pd.DataFrame(model.feature_importances_)\n",
    "    column_df     = pd.DataFrame(FEATURES)\n",
    "    coef_sumry    = (pd.merge(coefficients,column_df,left_index= True,\n",
    "                              right_index= True, how = \"left\"))\n",
    "    coef_sumry.columns = [\"coefficients\",\"features\"]\n",
    "    coef_sumry    = coef_sumry.sort_values(by = \"coefficients\",ascending = False)\n",
    "    plot4 = trace4 = go.Bar(x = coef_sumry[\"features\"],y = coef_sumry[\"coefficients\"],\n",
    "                    name = \"coefficients\",\n",
    "                    marker = dict(color = coef_sumry[\"coefficients\"],\n",
    "                                  colorscale = \"Picnic\",\n",
    "                                  line = dict(width = .6,color = \"black\")))\n",
    "\n",
    "\n",
    "    #Subplots\n",
    "\n",
    "    fig = plotly.subplots.make_subplots(rows=2, cols=2, specs=[[{}, {}], [{'colspan': 2}, None]],\n",
    "                            subplot_titles=('Confusion Matrix',\n",
    "                                            'Receiver operating characteristic',\n",
    "                                            'Feature Importances'),print_grid=False)\n",
    "    fig.append_trace(plot1,1,1)\n",
    "    fig.append_trace(plot2,1,2)\n",
    "    fig.append_trace(plot3,1,2)\n",
    "    fig.append_trace(plot4,2,1)\n",
    "    fig['layout'].update(showlegend=False, title=\"Model performance\" ,\n",
    "                         autosize = False,height = 900,width = 800,\n",
    "                         plot_bgcolor = 'rgba(240,240,240, 0.95)',\n",
    "                         paper_bgcolor = 'rgba(240,240,240, 0.95)',\n",
    "                         margin = dict(b = 195))\n",
    "    fig[\"layout\"][\"xaxis2\"].update(dict(title = \"false positive rate\"))\n",
    "    fig[\"layout\"][\"yaxis2\"].update(dict(title = \"true positive rate\"))\n",
    "    fig[\"layout\"][\"xaxis3\"].update(dict(showgrid = True,tickfont = dict(size = 10),\n",
    "                                        tickangle = 90))\n",
    "    py.iplot(fig);\n",
    "    print (\"ROC-AUC : \",model_roc_auc,\"\\n\")\n",
    "    print(\"score F1 : \", metrics.f1_score(Y, predict),\"\\n\")\n",
    "    print (\"Accuracy Score : \",metrics.accuracy_score(Y,predict))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_knn(model,X,Y):\n",
    "    model.fit(X,Y)\n",
    "    predict   = model.predict(X)\n",
    "    proba = model.predict_proba(X)\n",
    "    #roc_auc_score\n",
    "    model_roc_auc = metrics.roc_auc_score(Y,predict) \n",
    "    #plot confusion matrix\n",
    "    plot_confusion_matrix(model, X, Y)  \n",
    "    plt.show();\n",
    "    print (\"ROC-AUC : \",model_roc_auc,\"\\n\")\n",
    "    print(\"score F1 : \", metrics.f1_score(Y, predict),\"\\n\")\n",
    "    print (\"Accuracy Score : \",metrics.accuracy_score(Y,predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MetricsMaker(model):\n",
    "    # Save Models\n",
    "    # Splits\n",
    "    kf = StratifiedKFold(n_splits=5,shuffle=True,random_state=2021)\n",
    "    split = list(kf.split(train_X,train_Y))\n",
    "    Metrics = {}\n",
    "    Precision, Accuracy, F1_score, Recall_score, ROC_AUC = 0, 0, 0, 0, 0\n",
    "    for i,(train_index, test_index) in enumerate(split):\n",
    "\n",
    "        data_train = train_X[train_index] \n",
    "        y_train = train_Y[train_index] \n",
    "        data_test = train_X[test_index]\n",
    "        y_test = train_Y[test_index]\n",
    "\n",
    "        # create a fitted model\n",
    "        fittedModel = model.fit(data_train,y_train)\n",
    "        y_hat_proba = fittedModel.predict_proba(data_test)[:,1]\n",
    "        y_hat = fittedModel.predict(data_test)\n",
    "        #  log_l = \n",
    "        Precision += metrics.precision_score(y_test,y_hat)\n",
    "        Accuracy += metrics.accuracy_score(y_test,y_hat)\n",
    "        F1_score += metrics.f1_score(y_test,y_hat)\n",
    "        Recall_score += metrics.recall_score(y_test,y_hat)\n",
    "        ROC_AUC += metrics.roc_auc_score(y_test,y_hat)\n",
    "        \n",
    "    Metrics['Precision'] = Precision / 5 \n",
    "    Metrics['Accuracy'] = Accuracy / 5\n",
    "    Metrics['F1_score'] = F1_score / 5\n",
    "    Metrics['Recall_score'] = Recall_score / 5\n",
    "    Metrics['ROC-AUC'] = ROC_AUC / 5\n",
    "    \n",
    "    return Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les metrics scores de chaque modeles seront stockés ici!\n",
    "Metrics = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2<span style=\"color:black\"> Régression Logistique </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "parameters = {'Cs': [1, 2, 3, 4, 5, 6 ,7 ,8 ,9 ,10]\n",
    "             }\n",
    "\n",
    "logit = LogisticRegressionCV(random_state= 33,cv=10,max_iter=10000,verbose=1, n_jobs = -1)\n",
    "\n",
    "#tunning(parameters,logit,train_X,train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logReg = LogisticRegressionCV(Cs= 6, random_state= 33,cv=10,max_iter=10000,verbose=1)\n",
    "Metrics['LogisticRegressionCV'] = MetricsMaker(logReg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Evaluation avec le modèle tunné\n",
    "logit = LogisticRegressionCV(Cs= 6, random_state= 33,cv=10,max_iter=10000,verbose=1)\n",
    "evaluation(logit,\"coefficients\",train_X,train_Y)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3<span style=\"color:black\"> Decision Tree Classifier </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_t_c = DecisionTreeClassifier(random_state=33)\n",
    "parameters = {'max_depth': [1, 2, 3, 4, 5, 6, 7],\n",
    "              'max_features': [1, 2, 3, 4, 5],\n",
    "              'criterion': ['gini','entropy'],\n",
    "              'splitter': ['best'],\n",
    "              }\n",
    "    \n",
    "#tunning(parameters,d_t_c,train_X,train_Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_T_C =  DecisionTreeClassifier(random_state=33, criterion = \"gini\", max_depth=7, max_features = 5, splitter = \"best\")\n",
    "Metrics['DecisionTreeClassifier'] = MetricsMaker(D_T_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation avec le modèle tunné\n",
    "d_t_c =  DecisionTreeClassifier(random_state=33, criterion = \"gini\", max_depth=7, max_features = 5, splitter = \"best\")\n",
    "\n",
    "evaluation(d_t_c,\"features\",train_X,train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4<span style=\"color:black\"> SVC </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Le Tunning s'est fait un hyperparamètre à la fois malgrè que cela peut fausser les meilleurs combinaisons mais pour éviter une attente trop longue lors de l'execution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_v_c  = SVC(random_state=33,verbose=2)\n",
    "parameters = {'kernel': [\"linear\",\"rbf\",\"poly\"], \n",
    "              'gamma': [0.1, 1, 10, 100],\n",
    "              'C': [0.1, 1, 10, 100,1000],\n",
    "              'degree': [0, 1, 2, 3, 4, 5, 6]\n",
    "              }\n",
    "#tunning(parameters,s_v_c,train_X,train_Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_V_C =  SVC(random_state=33, kernel = \"rbf\", gamma=0.1, C = 10, degree = 4,probability=True,verbose=2 ) \n",
    "Metrics['SVC'] = MetricsMaker(S_V_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation avec le modèle tunné\n",
    "s_v_c =  SVC(random_state=33, kernel = \"rbf\", gamma=0.1, C = 10, degree = 4,probability=True,verbose=2 ) \n",
    "\n",
    "evaluation_knn(s_v_c,train_X,train_Y) #Since rbf Kernel is used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5<span style=\"color:black\"> KNN Classifier </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_n_n = KNeighborsClassifier(algorithm='auto', n_jobs = -1)\n",
    "\n",
    "parameters = {\n",
    "    'leaf_size':[5,10,20,30], \n",
    "    'n_neighbors':[3,4,5,8,10,11,12],\n",
    "    'weights' : ['uniform', 'distance'],\n",
    "    'p' : [1,2]\n",
    "}\n",
    "\n",
    "#tunning(parameters,k_n_n,train_X,train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_N_N = KNeighborsClassifier(algorithm='auto',leaf_size= 20,n_neighbors= 11, p=1, weights = \"distance\", n_jobs = -1)\n",
    "Metrics['KNeighborsClassifier'] = MetricsMaker(K_N_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation avec le modèle tunné\n",
    "k_n_n = KNeighborsClassifier(algorithm='auto',leaf_size= 20,n_neighbors= 11, p=1, weights = \"distance\", n_jobs = -1)\n",
    "\n",
    "evaluation_knn(k_n_n,train_X,train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6<span style=\"color:black\"> Random Forest Classifier </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_f_c = RandomForestClassifier(random_state=33, verbose=2,n_jobs = -1)\n",
    "parameters = {\n",
    "    'n_estimators': [5,10,15,20,30,40,50,60,70,80],\n",
    "    'min_samples_split': [3, 5, 10], \n",
    "    'max_depth': [2, 5, 15, 30,50,70,80],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'bootstrap': [True, False],\n",
    "    'criterion': ['gini','entropy']   \n",
    "}\n",
    "\n",
    "\n",
    "#tunning(parameters,r_f_c,train_X,train_Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_F_C = RandomForestClassifier(random_state=33, verbose=2, n_estimators = 70,\n",
    "                               min_samples_split= 3, max_depth = 70, max_features = \"auto\",\n",
    "                              bootstrap = \"False\", criterion = \"gini\")\n",
    "Metrics['RandomForestClassifier'] = MetricsMaker(R_F_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Evaluation avec le modèle tunné\n",
    "r_f_c = RandomForestClassifier(random_state=33, verbose=2, n_estimators = 70,\n",
    "                               min_samples_split= 3, max_depth = 70, max_features = \"auto\",\n",
    "                              bootstrap = \"False\", criterion = \"gini\")\n",
    "\n",
    "evaluation(r_f_c,\"features\",train_X,train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7<span style=\"color:black\"> Gradient boosting Classifier </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g_b_c = GradientBoostingClassifier (random_state = 33, verbose=2)\n",
    "parameters = {'learning_rate'    : [0.01,0.02,0.03,0.04,0.06,0.08,0.09],\n",
    "                  'loss'         : [\"deviance\", \"exponential\"],\n",
    "                  'subsample'    : [0.9, 0.5, 0.2, 0.1],\n",
    "                  'n_estimators' : [100,500,1000, 1500],\n",
    "                  'max_depth'    : [4,6,8,10],\n",
    "                  'criterion'    : [\"friedman_mse\", \"mse\"],\n",
    "                  'min_samples_split' : [2,4,6,8,10,12,14],\n",
    "                  'min_samples_leaf'  : [1,2,3,4],\n",
    "                  'max_features'      : [\"auto\", \"sqrt\", \"log2\"]\n",
    "            }\n",
    "\n",
    "#tunning(parameters,g_b_c,train_X,train_Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "G_B_C = GradientBoostingClassifier(learning_rate=0.09, n_estimators=500, max_depth = 8, min_samples_split = 12, \n",
    "         max_features='auto', subsample=0.1,criterion= \"friedman_mse\", min_samples_leaf = 2,\n",
    "         loss = \"exponential\", random_state=33, verbose = 1)\n",
    "Metrics['GradientBoostingClassifier'] = MetricsMaker(G_B_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Evaluation avec le modèle tunné\n",
    "g_b_c = GradientBoostingClassifier(learning_rate=0.09, n_estimators=500, max_depth = 8, min_samples_split = 12, \n",
    "         max_features='auto', subsample=0.1,criterion= \"friedman_mse\", min_samples_leaf = 2,\n",
    "         loss = \"exponential\", random_state=33, verbose = 1)\n",
    "evaluation(g_b_c,\"features\",train_X,train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.8<span style=\"color:black\"> XGBoost Classifier </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_g_c = XGBClassifier(use_label_encoder=False)\n",
    "\n",
    "parameters = {'nthread':[4,5,6,8,10,12], \n",
    "              'learning_rate': [0.01,0.03,0.05,0.1,0.2,0.3,0.4,0.5],\n",
    "              'max_depth': range (2, 21, 1),\n",
    "              'min_child_weight': [10,12,14,16,18,20],\n",
    "              'subsample': [0.6,0.8,1],\n",
    "              'colsample_bytree': [0.2,0.4,0.5,0.7],\n",
    "              'n_estimators': [100,200,300,400,500] \n",
    "              }\n",
    "\n",
    "#tunning(parameters,x_g_c,train_X,train_Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_G_B = XGBClassifier(learning_rate = 0.4,nthread = 10,max_depth = 16, subsample=0.8,colsample_bytree=0.5\n",
    "                      ,n_estimators = 200, min_child_weight = 16,\n",
    "              use_label_encoder=False, random_state = 33, verbosity=1)\n",
    "Metrics['XGBClassifier'] = MetricsMaker(X_G_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation avec le modèle tunné\n",
    "x_g_c = XGBClassifier(learning_rate = 0.4,nthread = 10,max_depth = 16, subsample=0.8,colsample_bytree=0.5\n",
    "                      ,n_estimators = 200, min_child_weight = 16,\n",
    "              use_label_encoder=False, random_state = 33, verbosity=1)\n",
    "\n",
    "evaluation(x_g_c,\"features\",train_X,train_Y.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.<span style=\"color:Turquoise\"> FEATURES SELECTION </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1<span style=\"color:black\"> Select KBest  </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kbest = SelectKBest(score_func=f_classif, k='all') #Score_func peut etre f_classif ou chi2\n",
    "fit = kbest.fit(train_X, train_Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=3) #Chaque score correspond à une colonne, les variables a retenir sont celles qui ont le meilleur score\n",
    "d = { label: value for label, value in zip(FEATURES, fit.scores_) }\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1<span style=\"color:black\"> RFECV avec XGboost Classifier tunné  </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = pd.DataFrame(train_X, columns = FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rfecv = RFECV(estimator=x_g_c,cv=5,scoring=\"f1\")   ## on peut choisir le min_features_to_select( 1 par défaut)\n",
    "rfecv = rfecv.fit(train_X, train_Y.values.ravel())\n",
    "\n",
    "print('Nombre optimal de variables :', rfecv.n_features_)\n",
    "print('Les meilleures variables :', train_X.columns[rfecv.support_])\n",
    "best_features = list(train_X.columns[rfecv.support_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.<span style=\"color:Purple\"> PREDICTION </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Les prédictions de la base test se feront avec chaque modèle tunné pour pouvoir comparer le meilleur modèle de classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Les métriques de comparaison**\n",
    "\n",
    "`recall` : Nombre de classes trouvées par rapport aux nombres entiers de cette même classe.\n",
    "\n",
    "`precision` : Combien de classes ont été correctements classifiées\n",
    "\n",
    "`f1-score` : La moyenne harmonique entre precision & recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(Metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
